# Q3 Results

|      Model      | Accuracy | Parameters (mil.) | Training Time (mins) |
|:---------------:|:--------:|:-----------------:|:--------------------:|
|     ResNet18    |   0.964  |        11.7       |         17.4         |
|    ResNet101    |   0.976  |        44.5       |         43.3         |
|      VGG19      |   0.964  |        143        |         17.5         |
|  WideResNet101  |   0.963  |       126.9       |         72.08        |
| ResNeXt50-32x4d |   0.956  |        25.5       |         28.43        |

From the results we can conclude that ResNet101 is the best performing model, with an accuracy of 0.976. This is followed by ResNet18 and VGG19, which both have an accuracy of 0.964. WideResNet101 and ResNeXt50-32x4d have an accuracy of 0.963 and 0.956 respectively. Notably, the more modern and complex models, WideResNet and ResNeXt, performed the wort out of the models evaluated. This may be due to the fact that the models were not trained for long enough, or that the models are not suitable for the dataset. However, the results are still promising, with all models achieving an accuracy of over 95%. The training time of each model is also shown, with ResNet18 being the fastest to train, and WideResNet101 being the slowest. This is expected, as ResNet18 has the least number of parameters, and WideResNet101 has the most (neglecting VGG19). VGG19, despite having the most parameters, was the second fastest to train. This is likely due to the relative simplicity of the model, with the majority of the parameters being in the final fully connected layers.

Another interesting result from the training is the distribution of true positive (TP), and false negatie (FN) results. The base ResNets and ResNeXt produced FP and FN results of near equal value, variations of approximately 70, 20 and 50 results for ResNet18 and ResNet101 and ResNeXt respectively. However, the other models produced significantly more biased results. VGG19 heavily leans towards false negative results, with around 200 more FN results than FP. WideResNet101, on the other hand, produced around 200 more FP results than FN. This comparison of FP and FN results are an important consideration in model choice, depending on the application. For example, for a more conservative estimator, a higher FN rate might be prefered to ensure less FP results get through. (i.e. less ai generated images are evaluated as real).

Note: Training times were found from training locally on an M1 Macbook Pro with 16GB of RAM. The training times will vary depending on the hardware used.